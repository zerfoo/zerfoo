package loss // import "github.com/zerfoo/zerfoo/training/loss"

training/loss/cross_entropy_loss.go

TYPES

type CrossEntropyLoss[T tensor.Numeric] struct {
	// Has unexported fields.
}
    CrossEntropyLoss computes the cross-entropy loss.

func NewCrossEntropyLoss[T tensor.Numeric](engine compute.Engine[T]) *CrossEntropyLoss[T]
    NewCrossEntropyLoss creates a new CrossEntropyLoss layer.

func (cel *CrossEntropyLoss[T]) Backward(ctx context.Context, dOut *tensor.Tensor[T], inputs ...*tensor.Tensor[T]) ([]*tensor.Tensor[T], error)
    Backward computes the gradients for CrossEntropyLoss. dOut is typically a
    scalar (1.0) for loss functions.

func (cel *CrossEntropyLoss[T]) Forward(ctx context.Context, inputs ...*tensor.Tensor[T]) (*tensor.Tensor[T], error)
    Forward computes the cross-entropy loss. Inputs: predictions (logits),
    targets (int labels).

func (cel *CrossEntropyLoss[T]) OutputShape(inputShapes ...[]int) ([]int, error)
    OutputShape returns the output shape of the loss (a scalar).

func (cel *CrossEntropyLoss[T]) Parameters() []graph.Parameter[T]
    Parameters returns an empty slice as CrossEntropyLoss has no trainable
    parameters.

type Loss[T tensor.Numeric] interface {
	// Forward computes the loss and its gradient.
	Forward(predictions, targets *tensor.Tensor[T]) (T, *tensor.Tensor[T])
}
    Loss defines the interface for loss functions.

type MSE[T tensor.Numeric] struct {
	// Has unexported fields.
}
    MSE calculates the mean squared error between predictions and targets.

func NewMSE[T tensor.Numeric](engine compute.Engine[T], ops numeric.Arithmetic[T]) *MSE[T]

func (m *MSE[T]) Backward(predictions, targets *tensor.Tensor[T]) *tensor.Tensor[T]
    Backward computes the initial gradient of the loss.

func (m *MSE[T]) Forward(predictions, targets *tensor.Tensor[T]) *tensor.Tensor[T]
    Forward computes the loss value.

