package optimizer // import "github.com/zerfoo/zerfoo/training/optimizer"

training/optimizer/adamw.go

TYPES

type AdamW[T tensor.Numeric] struct {
	// Has unexported fields.
}
    AdamW implements the AdamW optimizer.

func NewAdamW[T tensor.Numeric](engine compute.Engine[T], learningRate, beta1, beta2, epsilon, weightDecay T) *AdamW[T]
    NewAdamW creates a new AdamW optimizer.

func (a *AdamW[T]) Step(ctx context.Context, params []graph.Parameter[T]) error
    Step updates the parameters based on their gradients.

type Optimizer[T tensor.Numeric] interface {
	Step(params []*graph.Parameter[T])
	Clip(params []*graph.Parameter[T], threshold float32)
}
    Optimizer defines the interface for optimization algorithms.

type SGD[T tensor.Numeric] struct {
	// Has unexported fields.
}
    SGD implements the stochastic gradient descent optimizer.

func NewSGD[T tensor.Numeric](engine compute.Engine[T], ops numeric.Arithmetic[T], learningRate float32) *SGD[T]

func (s *SGD[T]) Clip(params []*graph.Parameter[T], threshold float32)

func (s *SGD[T]) Step(params []*graph.Parameter[T])
    Step updates the parameters based on their gradients.

